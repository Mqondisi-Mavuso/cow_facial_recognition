{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c32027f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb9d6e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Downloading Dataset Version Zip in Thecowface-1 to yolov8: 100% [7540144 / 7540144] bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Dataset Version Zip to Thecowface-1 in yolov8:: 100%|████████████████████████| 282/282 [00:00<00:00, 603.51it/s]\n"
     ]
    }
   ],
   "source": [
    "# This is for downloading the YOLOv8 cow face images and labels\n",
    "#!pip install roboflow\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"my_api_here\")                    #remeber to commit this to public repo\n",
    "project = rf.workspace(\"face-cow\").project(\"thecowface\")\n",
    "dataset = project.version(1).download(\"yolov8\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3afefb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72f8b89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the model to segment the cow face using custom dataset \n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov8n-seg.pt\")  # load a pretrained model (recommended for training)\n",
    "# Train the model\n",
    "model.train(data=\"data.yaml\", epochs=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f3981c",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## Cow Face Segmentation Above ######################### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87528440",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## Cow Face Identification below ######################### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "518c20b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7ec28d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the videos to read each frame \n",
    "cap = cv2.VideoCapture(\"DATA/test/c22/IMG_3751.MOV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5cd1c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of frames\n",
    "num_frame = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63f82078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display image function\n",
    "def show_pic(img_cross):\n",
    "    fig = plt.figure(figsize=(15,15))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(img_cross, cmap = \"gray\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7787724",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the frames from each video\n",
    "def get_frames(num_frame):\n",
    "    for frame in range(num_frame//2):\n",
    "        ret, img = cap.read()\n",
    "        # this rotates the image before writing to file\n",
    "        rotated_img = cv2.rotate(img, cv2.ROTATE_180)        \n",
    "        if ret == False:\n",
    "            break\n",
    "        else:\n",
    "            path = r\"DATA/test/c22\"\n",
    "            name = f'/b_c{frame + 1}.jpg' \n",
    "            # write the file\n",
    "            cv2.imwrite(f'{path}{name}', rotated_img)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11768876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this call will write the images to our training folder \n",
    "get_frames(num_frame=num_frame)\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dddc8bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7de8412a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gen = ImageDataGenerator(rotation_range=30,\n",
    "                               width_shift_range=0.1,\n",
    "                               height_shift_range=0.1,\n",
    "                               rescale=1/255,\n",
    "                               shear_range=0.2,\n",
    "                               zoom_range=0.2,\n",
    "                               horizontal_flip=True,\n",
    "                               fill_mode=\"nearest\"                                \n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f18e2036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13308 images belonging to 22 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.image.DirectoryIterator at 0x1fbc4c97d00>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_gen.flow_from_directory(\"DATA/train/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6b6c5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll use this shape for all the images \n",
    "input_shape = (550, 960, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51ab32f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "the_cow = cv2.imread('DATA/train/c1/a_c102.jpg')\n",
    "the_cow = cv2.cvtColor(the_cow, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e606cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3840, 2160, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "the_cow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd4bc60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resized = cv2.resize(the_cow, (550, 960), interpolation = cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e50be134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(960, 550, 3)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12c0d3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_pic(image_gen.random_transform(resized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21b0d268",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Conv2D, MaxPooling2D, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3534e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# adding our convulutional nueral network layers \n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=input_shape, activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "          \n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), input_shape=input_shape, activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "          \n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), input_shape=input_shape, activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "          \n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "# the dropout layer reduces overfitting by randomly turning off nuerons during training \n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# the output is binary, either cow1 or cow.. hence Dense layer is just one\n",
    "model.add(Dense(1))\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "          \n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "             optimizer=\"adam\",\n",
    "             metrics=[\"accuracy\"]\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16aba84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5774e19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13308 images belonging to 22 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "# here we are just pointing the iterator to the path with the training data\n",
    "train_img_gen = image_gen.flow_from_directory(\"DATA/train/\",\n",
    "                                             target_size=input_shape[:2],\n",
    "                                             batch_size=batch_size,\n",
    "                                             class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5be8baaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to see how the data classes will be presented \n",
    "train_img_gen.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6300a2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3269 images belonging to 22 classes.\n"
     ]
    }
   ],
   "source": [
    "test_img_gen = image_gen.flow_from_directory(\"DATA/test/\",\n",
    "                                             target_size=input_shape[:2],\n",
    "                                             batch_size=batch_size,\n",
    "                                             class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca564e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "150/150 [==============================] - 1107s 7s/step - loss: 0.2830 - accuracy: 0.9409 - val_loss: 0.1895 - val_accuracy: 0.9545\n",
      "Epoch 2/5\n",
      "150/150 [==============================] - 1249s 8s/step - loss: 0.1934 - accuracy: 0.9545 - val_loss: 0.1854 - val_accuracy: 0.9545\n",
      "Epoch 3/5\n",
      "150/150 [==============================] - 1189s 8s/step - loss: 0.1926 - accuracy: 0.9545 - val_loss: 0.1864 - val_accuracy: 0.9545\n",
      "Epoch 4/5\n",
      "150/150 [==============================] - 1121s 7s/step - loss: 0.1921 - accuracy: 0.9545 - val_loss: 0.1888 - val_accuracy: 0.9545\n",
      "Epoch 5/5\n",
      "150/150 [==============================] - 1079s 7s/step - loss: 0.1917 - accuracy: 0.9545 - val_loss: 0.1858 - val_accuracy: 0.9545\n"
     ]
    }
   ],
   "source": [
    "# training the model on our images \n",
    "results = model.fit(train_img_gen, epochs=5, steps_per_epoch=150,\n",
    "                             validation_data=test_img_gen, validation_steps=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "da71bec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1fbc78c6880>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# saving the model \n",
    "#model.save(\"Cow_model.h5\")\n",
    "# now we evaluate the model \n",
    "plt.plot(results.history[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5f00d3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v2 as tf\n",
    "from keras.preprocessing import image\n",
    "\n",
    "# the_cow_1 = cv2.imread('DATA/train/c1/a_c102.jpg')\n",
    "\n",
    "# the_cow_1 = image.load_img(the_cow_1, target_size=(960, 550))\n",
    "\n",
    "# the_cow_1 = image.img_to_array(the_cow_1)\n",
    "\n",
    "# the_cow_1 = np.expand_dims(the_cow_1, axis=0)\n",
    "# the_cow_1 = the_cow_1/255\n",
    "\n",
    "the_cow_1 = tf.keras.utils.load_img('DATA/test/fake/false3.jpg', target_size=(550, 960))\n",
    "input_arr = tf.keras.utils.img_to_array(the_cow_1)\n",
    "input_arr = np.array([input_arr])  # Convert single image to a batch.\n",
    "input_arr = input_arr/255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea75f18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_gen.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e7edc1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 171ms/step\n"
     ]
    }
   ],
   "source": [
    "#prediction_prob = model.predict(the_cow_1)\n",
    "#predictions = model.predict_classes(input_arr)\n",
    "\n",
    "predicted = np.argmax(model.predict(input_arr),axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
